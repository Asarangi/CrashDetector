{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore, Experiment\n",
    "import azureml.data\n",
    "from azureml.data.azure_storage_datastore import AzureFileDatastore, AzureBlobDatastore\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/dg595/CrashDetection/Azure/config.json\n",
      "Workspace name: AccidentDetection\n",
      "Azure region: eastus\n",
      "Subscription id: e298a653-a33f-4b32-9ec2-2adfbd3b649d\n",
      "Resource group: CCGroup7Resources\n"
     ]
    }
   ],
   "source": [
    "# Retreive Existing Workspace\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-25af744d51b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create Azure ML Experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscript_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;31m##FOLDER THAT HOLDS THE TRAINING SCRIPT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/crash/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "# Create Azure ML Experiment \n",
    "script_folder = '' ##FOLDER THAT HOLDS THE TRAINING SCRIPT\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registering our Blob storage in our workspace\n",
    "ds = Datastore.register_azure_blob_container(workspace=ws,\n",
    "                                             datastore_name='dashcamstreetimages',\n",
    "                                             container_name='imageblob',\n",
    "                                             account_name='dashcamstreetimages',\n",
    "                                             account_key='9/q6ErflYUj2sUEx1KhJQDhwcGDoujlCE5NTQIr7ohviuhPODHt4weQ2el++zPNc7RYM+QPY3Tz9jIK0O8rJlg==',\n",
    "                                             create_if_not_exists=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspaceblobstore AzureBlob\n",
      "workspacefilestore AzureFile\n",
      "dashcamstreetimages AzureBlob\n"
     ]
    }
   ],
   "source": [
    "#list all datastores registered in current workspace\n",
    "datastores = ws.datastores\n",
    "for name, ds in datastores.items():\n",
    "    print(name, ds.datastore_type)\n",
    "    \n",
    "\n",
    "#define default datastore for current workspace\n",
    "ws.set_default_datastore('dashcamstreetimages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_001.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_002.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_003.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_004.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_005.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_006.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_007.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_008.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_009.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_010.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_011.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_012.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_013.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_014.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_015.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_016.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_017.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_018.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_019.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_020.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_021.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_022.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_023.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_024.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_025.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_026.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_027.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_028.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_029.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_030.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_031.npz\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_032.npz\n",
      "Uploaded ../Anticipating-Accidents/dataset/features/testing/batch_001.npz, 1 files out of an estimated total of 174\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_033.npz\n",
      "Uploaded ../Anticipating-Accidents/dataset/features/testing/batch_006.npz, 2 files out of an estimated total of 174\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_034.npz\n",
      "Uploaded ../Anticipating-Accidents/dataset/features/testing/batch_003.npz, 3 files out of an estimated total of 174\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_035.npz\n",
      "Uploaded ../Anticipating-Accidents/dataset/features/testing/batch_026.npz, 4 files out of an estimated total of 174\n",
      "Uploading ../Anticipating-Accidents/dataset/features/testing/batch_036.npz\n"
     ]
    }
   ],
   "source": [
    "# Upload data directory to datastore\n",
    "ds.upload(src_dir='../Anticipating-Accidents/dataset/features',\n",
    "          target_path='features',\n",
    "          overwrite=True,\n",
    "          show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " config.json  'Data Upload.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:crash]",
   "language": "python",
   "name": "conda-env-crash-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
