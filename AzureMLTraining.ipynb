{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore, Experiment\n",
    "import azureml.data\n",
    "from azureml.data.azure_storage_datastore import AzureFileDatastore, AzureBlobDatastore\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/dg595/CrashDetection/Azure/config.json\n",
      "Workspace name: AccidentDetection\n",
      "Azure region: eastus\n",
      "Subscription id: e298a653-a33f-4b32-9ec2-2adfbd3b649d\n",
      "Resource group: CCGroup7Resources\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach to existing DataStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Datastore.get(ws, datastore_name='dashcamstreetimages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_dashcamstreetimages"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.as_mount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Attach existing AmlCompute\n",
    "Create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) to train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we could not find the cluster with the given name, then we will create a new cluster here. We will create an `AmlCompute` cluster of `STANDARD_NC6` GPU VMs. This process is broken down into 3 steps:\n",
    "1. create the configuration (this step is local and only takes a second)\n",
    "2. create the cluster (this step will take about **20 seconds**)\n",
    "3. provision the VMs to bring the cluster to the initial size (of 1 in this case). This step will take about **3-5 minutes** and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-04-21T19:14:22.263000+00:00', 'errors': None, 'creationTime': '2019-04-18T23:11:51.292045+00:00', 'modifiedTime': '2019-04-18T23:12:07.921232+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "cluster_name = \"crash\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crash AmlCompute Succeeded\n"
     ]
    }
   ],
   "source": [
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, ct.type, ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TensorFlow estimator & add Keras\n",
    "Next, we construct an `azureml.train.dnn.TensorFlow` estimator object, use the `gpucluster` as compute target, and pass the mount-point of the datastore to the training code as a parameter.\n",
    "The TensorFlow estimator is providing a simple way of launching a TensorFlow training job on a compute target. It will automatically provide a docker image that has TensorFlow installed. In this case, we add `keras` package (for the Keras framework obviously), and `matplotlib` package for plotting a \"Loss vs. Accuracy\" chart and record it in run history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "framework_version is not specified, defaulting to version 1.12.\n"
     ]
    }
   ],
   "source": [
    "# Train using Tensorflow\n",
    "from azureml.train.dnn import TensorFlow\n",
    "exp = Experiment(workspace=ws, name='AccidentDetection')\n",
    "script_params = {\n",
    "    '--data_dir': ds.as_mount(),\n",
    "    '--mode': 'train',\n",
    "    '--gpu': 0,\n",
    "}\n",
    "\n",
    "tf_est = TensorFlow(source_directory='Anticipating-Accidents/',\n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='accident.py',\n",
    "                    conda_packages=['opencv'],\n",
    "                    pip_packages=['keras', 'matplotlib'],\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job to run\n",
    "Submit the estimator to the Azure ML experiment to kick off the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submitting /home/dg595/CrashDetection/Azure/Anticipating-Accidents directory for run. The size of the directory >= 25 MB, so it can take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "run = exp.submit(tf_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the Run\n",
    "As the Run is executed, it will go through the following stages:\n",
    "1. Preparing: A docker image is created matching the Python environment specified by the TensorFlow estimator and it will be uploaded to the workspace's Azure Container Registry. This step will only happen once for each Python environment -- the container will then be cached for subsequent runs. Creating and uploading the image takes about **5 minutes**. While the job is preparing, logs are streamed to the run history and can be viewed to monitor the progress of the image creation.\n",
    "\n",
    "2. Scaling: If the compute needs to be scaled up (i.e. the AmlCompute cluster requires more nodes to execute the run than currently available), the cluster will attempt to scale up in order to make the required amount of nodes available. Scaling typically takes about **5 minutes**.\n",
    "\n",
    "3. Running: All scripts in the script folder are uploaded to the compute target, data stores are mounted/copied and the `entry_script` is executed. While the job is running, stdout and the `./logs` folder are streamed to the run history and can be viewed to monitor the progress of the run.\n",
    "\n",
    "4. Post-Processing: The `./outputs` folder of the run is copied over to the run history\n",
    "\n",
    "There are multiple ways to check the progress of a running job. We can use a Jupyter notebook widget. \n",
    "\n",
    "**Note: The widget will automatically update ever 10-15 seconds, always showing you the most up-to-date information about the run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6970897dfe91475082a9803d85593e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>AccidentDetection</td><td>AccidentDetection_1556475402_29a7a716</td><td>azureml.scriptrun</td><td>Running</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/e298a653-a33f-4b32-9ec2-2adfbd3b649d/resourceGroups/CCGroup7Resources/providers/Microsoft.MachineLearningServices/workspaces/AccidentDetection/experiments/AccidentDetection/runs/AccidentDetection_1556475402_29a7a716\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: AccidentDetection,\n",
       "Id: AccidentDetection_1556475402_29a7a716,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from outputs/model/checkpoint to ./model/checkpoint ...\n",
      "Downloading from outputs/model/final_model.data-00000-of-00001 to ./model/final_model.data-00000-of-00001 ...\n",
      "Downloading from outputs/model/final_model.index to ./model/final_model.index ...\n",
      "Downloading from outputs/model/final_model.meta to ./model/final_model.meta ...\n",
      "Downloading from outputs/model/model-10.data-00000-of-00001 to ./model/model-10.data-00000-of-00001 ...\n",
      "Downloading from outputs/model/model-10.index to ./model/model-10.index ...\n",
      "Downloading from outputs/model/model-10.meta to ./model/model-10.meta ...\n",
      "Downloading from outputs/model/model-15.data-00000-of-00001 to ./model/model-15.data-00000-of-00001 ...\n",
      "Downloading from outputs/model/model-15.index to ./model/model-15.index ...\n",
      "Downloading from outputs/model/model-15.meta to ./model/model-15.meta ...\n",
      "Downloading from outputs/model/model-20.data-00000-of-00001 to ./model/model-20.data-00000-of-00001 ...\n",
      "Downloading from outputs/model/model-20.index to ./model/model-20.index ...\n",
      "Downloading from outputs/model/model-20.meta to ./model/model-20.meta ...\n",
      "Downloading from outputs/model/model-25.data-00000-of-00001 to ./model/model-25.data-00000-of-00001 ...\n",
      "Downloading from outputs/model/model-25.index to ./model/model-25.index ...\n",
      "Downloading from outputs/model/model-25.meta to ./model/model-25.meta ...\n",
      "Downloading from outputs/model/model-30.data-00000-of-00001 to ./model/model-30.data-00000-of-00001 ...\n",
      "Downloading from outputs/model/model-30.index to ./model/model-30.index ...\n",
      "Downloading from outputs/model/model-30.meta to ./model/model-30.meta ...\n",
      "Downloading from outputs/model/model-5.data-00000-of-00001 to ./model/model-5.data-00000-of-00001 ...\n",
      "Downloading from outputs/model/model-5.index to ./model/model-5.index ...\n",
      "Downloading from outputs/model/model-5.meta to ./model/model-5.meta ...\n"
     ]
    }
   ],
   "source": [
    "# create a model folder in the current directory\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "\n",
    "for f in run.get_file_names():\n",
    "    if f.startswith('outputs/model'):\n",
    "        output_file_path = os.path.join('./model', f.split('/')[-1])\n",
    "        print('Downloading from {} to {} ...'.format(f, output_file_path))\n",
    "        run.download_file(name=f, output_file_path=output_file_path)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run.register_model(model_name='crash-detection', model_path='outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:crash]",
   "language": "python",
   "name": "conda-env-crash-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
